{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Car Prices Using K-nearest Neighbors\n",
    "\n",
    "In this project, I will use the K-nearest neighbors model to predict a car's market price using its attributes. The data set I will be working with contains information on various cars. For each car I have information about the technical aspects of the vehicle such as the motor's displacement, the weight of the car, the miles per gallon, how fast the car accelerates, and more. The data set can be downloaded [here](https://archive.ics.uci.edu/ml/datasets/automobile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,KFold\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name columns \n",
    "cols = ['symboling', 'normalized-losses', 'make', 'fuel-type', 'aspiration', 'num-of-doors', 'body-style', \n",
    "        'drive-wheels', 'engine-location', 'wheel-base', 'length', 'width', 'height', 'curb-weight', 'engine-type', \n",
    "        'num-of-cylinders', 'engine-size', 'fuel-system', 'bore', 'stroke', 'compression-rate', 'horsepower', 'peak-rpm', 'city-mpg', 'highway-mpg', 'price']\n",
    "cars=pd.read_csv('imports-85.data',names=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the data\n",
    "print(cars.head())\n",
    "print('\\n')\n",
    "print(cars.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean missing data\n",
    "cars.replace('?',np.nan,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare numerical columns\n",
    "numerical_cols=['normalized-losses', 'wheel-base', 'length',\n",
    "                'width', 'height', 'curb-weight','engine-size', 'bore', \n",
    "                'stroke', 'compression-rate','horsepower', \n",
    "                'peak-rpm', 'city-mpg', 'highway-mpg', 'price']\n",
    "\n",
    "# Set these columns in float type\n",
    "cars_numerical=cars[numerical_cols].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing price \n",
    "cars_numerical.dropna(subset=['price'],inplace=True)\n",
    "\n",
    "# Replace missing values using the average values of that column\n",
    "cars_numerical.fillna(cars_numerical.mean(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescaling the data using min-max normalization except the price column\n",
    "scaler=MinMaxScaler()\n",
    "cars_numerical_scaled=scaler.fit_transform(cars_numerical.drop('price',axis=1))\n",
    "cars_numerical_scaled=pd.DataFrame(cars_numerical_scaled,columns=cars_numerical.columns.drop('price'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Univariate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that returns the root mean square error using a single feature\n",
    "def knn_train_test(train_col,target_col):\n",
    "    X=cars_numerical_scaled[[train_col]]\n",
    "    y=cars_numerical[target_col]\n",
    "    \n",
    "    # Split the data into two halfs: train/test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.5, random_state=1)\n",
    "    \n",
    "    # Apply K-neighbor regression\n",
    "    knn=KNeighborsRegressor()\n",
    "    knn.fit(X_train,y_train)\n",
    "    predictions=knn.predict(X_test)\n",
    "    rmse=mean_squared_error(y_test,predictions)**(1/2)\n",
    "    return rmse\n",
    "\n",
    "feature_cols=cars_numerical.columns.drop('price')\n",
    "one_fea_rmses={}\n",
    "\n",
    "# Calculate root mean square error for each feature\n",
    "for col in feature_cols:\n",
    "    one_fea_rmses[col]=knn_train_test(col,'price')\n",
    "one_fea_rmses=pd.Series(one_fea_rmses)\n",
    "one_fea_rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate RMSEs using different k values\n",
    "def knn_train_test_k(train_col,target_col):\n",
    "    X=cars_numerical_scaled[[train_col]]\n",
    "    y=cars_numerical[target_col]\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.5, random_state=1)\n",
    "    k_values=[1,3,5,7,9]\n",
    "    k_rmses={}\n",
    "    for k in k_values:\n",
    "        \n",
    "        # Fit model using k-nearest neighbors\n",
    "        knn=KNeighborsRegressor(n_neighbors=k)\n",
    "        knn.fit(X_train,y_train)\n",
    "        predictions=knn.predict(X_test)\n",
    "        rmse=mean_squared_error(y_test,predictions)**(1/2)\n",
    "        k_rmses[k]=rmse\n",
    "    return k_rmses\n",
    "\n",
    "k_one_fea_rmses={}\n",
    "for col in feature_cols:\n",
    "    k_one_fea_rmses[col]=knn_train_test_k(col,'price')\n",
    "k_one_fea_rmses=pd.DataFrame(k_one_fea_rmses)\n",
    "k_one_fea_rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot RMSE of each feature using different k values\n",
    "k_one_fea_rmses.plot()\n",
    "plt.xticks([1,3,5,7,9])\n",
    "plt.legend(bbox_to_anchor=(1.05, 1),loc='upper left')\n",
    "plt.xlabel('k value')\n",
    "plt.ylabel('RMSE')\n",
    "\n",
    "# Engine-size is the best feature to predict price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that returns RMSEs using multiple best features\n",
    "def knn_train_test_multi(train_cols,target_col):\n",
    "    X=cars_numerical_scaled[train_cols]\n",
    "    y=cars_numerical[target_col]\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.5, random_state=1)\n",
    "    knn=KNeighborsRegressor()\n",
    "    knn.fit(X_train,y_train)\n",
    "    predictions=knn.predict(X_test)\n",
    "    rmse=mean_squared_error(y_test,predictions)**(1/2)\n",
    "    return rmse\n",
    "\n",
    "# Sort best features in ascending order\n",
    "best_features=one_fea_rmses.sort_values()\n",
    "multi_fea_rmses={}\n",
    "for n_fea in range(2,6):\n",
    "    \n",
    "    # Return results for best 2, 3, 4, 5 features\n",
    "    train_cols=best_features.index[:n_fea]\n",
    "    multi_fea_rmses['{} best features'.format(n_fea)]=knn_train_test_multi(train_cols,'price')\n",
    "multi_fea_rmses\n",
    "# Four best feature generate smallest RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that returns RMSEs using different k values\n",
    "def knn_train_test_multi_k(train_cols,target_col):\n",
    "    X=cars_numerical_scaled[train_cols]\n",
    "    y=cars_numerical[target_col]\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.5, random_state=1)\n",
    "    k_values=range(1,26)\n",
    "    k_rmses={}\n",
    "    for k in k_values:\n",
    "        \n",
    "        # Fit the model with k-nearest neighbors\n",
    "        knn=KNeighborsRegressor(n_neighbors=k)\n",
    "        knn.fit(X_train,y_train)\n",
    "        predictions=knn.predict(X_test)\n",
    "        rmse=mean_squared_error(y_test,predictions)**(1/2)\n",
    "        k_rmses[k]=rmse\n",
    "    return k_rmses\n",
    "\n",
    "k_multi_fea_rmses={}\n",
    "for n_fea in range(2,6):\n",
    "    train_cols=best_features.index[:n_fea]\n",
    "    k_multi_fea_rmses['{} best features'.format(n_fea)]=knn_train_test_multi_k(train_cols,'price')\n",
    "k_multi_fea_rmses=pd.DataFrame(k_multi_fea_rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_multi_fea_rmses.plot()\n",
    "plt.xlabel('k value')\n",
    "plt.ylabel('RMSE')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold Cross Validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that returns RMSEs using multiple best features\n",
    "def knn_cross_val(train_col,target_col):\n",
    "    kf=KFold(n_splits=5, shuffle=True,random_state=1)\n",
    "    knn=KNeighborsRegressor()\n",
    "    mses=cross_val_score(knn,cars_numerical_scaled[[train_col]],cars_numerical[target_col],scoring='neg_mean_squared_error',cv=kf)\n",
    "    rmses = np.sqrt(np.absolute(mses))\n",
    "    avg_rmse = np.mean(rmses)\n",
    "    return avg_rmse\n",
    "\n",
    "cross_val_rmses={}\n",
    "for col in feature_cols:\n",
    "    cross_val_rmses[col]=knn_cross_val(col,'price')\n",
    "cross_val_rmses=pd.Series(cross_val_rmses)\n",
    "cross_val_rmses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that returns RMSEs for different k-fold values\n",
    "def knn_cross_val_k_fold(train_col,target_col):\n",
    "    avg_rmses={}\n",
    "    for k in range(2,21):\n",
    "        kf=KFold(n_splits=k, shuffle=True,random_state=1)\n",
    "        knn=KNeighborsRegressor()\n",
    "        mses=cross_val_score(knn,cars_numerical_scaled[[train_col]],cars_numerical[target_col],scoring='neg_mean_squared_error',cv=kf)\n",
    "        rmses = np.sqrt(np.absolute(mses))\n",
    "        avg_rmse = np.mean(rmses)\n",
    "        avg_rmses[k]= avg_rmse\n",
    "    return avg_rmses\n",
    "\n",
    "k_fold_cross_val_rmses={}\n",
    "for col in feature_cols:\n",
    "    k_fold_cross_val_rmses[col]=knn_cross_val_k_fold(col,'price')\n",
    "k_fold_cross_val_rmses=pd.DataFrame(k_fold_cross_val_rmses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_cross_val_rmses.plot()\n",
    "plt.xticks(range(2,21))\n",
    "plt.legend(bbox_to_anchor=(1.05, 1),loc='upper left')\n",
    "plt.xlabel('k value')\n",
    "plt.ylabel('RMSE')\n",
    "\n",
    "# Engine-size is proved to be the best feature to predict car price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
